# ============================================================
# ğŸ“˜ Document Image Preprocessing Pipeline
# ============================================================
import os
import cv2
import torch
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import albumentations as A
from albumentations.pytorch import ToTensorV2

# ============================================================
# 1ï¸âƒ£ ì‹œë“œ ê³ ì • (ì¬í˜„ì„± ë³´ì¥)
# ============================================================
def set_seed(seed=42):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# ============================================================
# 2ï¸âƒ£ ê²½ë¡œ ì„¤ì •
# ============================================================
BASE_DIR = '/root/cv_project/data'
TRAIN_CSV = os.path.join(BASE_DIR, 'train.csv')
TEST_CSV = os.path.join(BASE_DIR, 'sample_submission.csv')
TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'train')
TEST_IMG_DIR = os.path.join(BASE_DIR, 'test')

SAVE_DIR = os.path.join(BASE_DIR, 'processed')
os.makedirs(SAVE_DIR, exist_ok=True)

# ============================================================
# 3ï¸âƒ£ Albumentations ì „ì²˜ë¦¬ ì •ì˜
# ============================================================
train_transform = A.Compose([
    A.Resize(512, 512),
    A.RandomRotate90(p=0.3),
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),
    A.RandomBrightnessContrast(p=0.4),
    A.GaussNoise(p=0.3),
    A.Perspective(p=0.3),
    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
    ToTensorV2()
])

test_transform = A.Compose([
    A.Resize(512, 512),
    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),
    ToTensorV2()
])

# ============================================================
# 4ï¸âƒ£ Custom Dataset
# ============================================================
class DocumentImageDataset(Dataset):
    def __init__(self, csv_path, img_dir, transform=None):
        self.df = pd.read_csv(csv_path)
        self.img_dir = img_dir
        self.transform = transform

        # ì»¬ëŸ¼ ìë™ íƒìƒ‰
        self.id_col = [c for c in self.df.columns if 'id' in c.lower() or 'file' in c.lower()]
        self.label_col = [c for c in self.df.columns if c.lower() in ['label', 'target', 'class']]

        self.id_col = self.id_col[0] if self.id_col else self.df.columns[0]
        self.label_col = self.label_col[0] if self.label_col else None

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_id = str(row[self.id_col])
        img_path = os.path.join(self.img_dir, f"{img_id}.jpg")

        if not os.path.exists(img_path):
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {img_path}")

        img = np.array(Image.open(img_path).convert("RGB"))
        label = int(row[self.label_col]) if self.label_col else -1

        if self.transform:
            img = self.transform(image=img)['image']
        return img, label

# ============================================================
# 5ï¸âƒ£ ë°ì´í„°ì…‹ ë¡œë“œ ë° ì €ì¥
# ============================================================
def save_preprocessed_tensors(dataset, name="train"):
    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)
    all_images, all_labels = [], []

    print(f"ğŸ”¹ {name} ë°ì´í„° ì „ì²˜ë¦¬ ë° í…ì„œ ì €ì¥ ì¤‘...")
    for imgs, labels in tqdm(loader):
        all_images.append(imgs)
        all_labels.append(labels)

    all_images = torch.cat(all_images)
    all_labels = torch.cat(all_labels)

    torch.save({
        'images': all_images,
        'labels': all_labels
    }, os.path.join(SAVE_DIR, f'{name}_processed.pt'))

    print(f"âœ… {name}_processed.pt ì €ì¥ ì™„ë£Œ ({all_images.shape[0]}ê°œ ì´ë¯¸ì§€)")

# ============================================================
# 6ï¸âƒ£ ì‹¤í–‰ (Train/Test ìë™ ì²˜ë¦¬)
# ============================================================
if __name__ == "__main__":
    print("ğŸ“˜ ë¬¸ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")

    train_dataset = DocumentImageDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)
    test_dataset = DocumentImageDataset(TEST_CSV, TEST_IMG_DIR, transform=test_transform)

    save_preprocessed_tensors(train_dataset, name="train")
    save_preprocessed_tensors(test_dataset, name="test")

    print("âœ¨ ëª¨ë“  ì „ì²˜ë¦¬ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ")
