{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930c6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ ë¬¸ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘\n",
      "ğŸ”¹ train ë°ì´í„° ì „ì²˜ë¦¬ ë° í…ì„œ ì €ì¥ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_58246/1468089281.py\", line 87, in __getitem__\n    raise FileNotFoundError(f\"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {img_path}\")\nFileNotFoundError: ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: /root/cv_project/data/train/002f99746285dfdd.jpg.jpg\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m DocumentImageDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform\u001b[38;5;241m=\u001b[39mtrain_transform)\n\u001b[1;32m    125\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DocumentImageDataset(TEST_CSV, TEST_IMG_DIR, transform\u001b[38;5;241m=\u001b[39mtest_transform)\n\u001b[0;32m--> 127\u001b[0m \u001b[43msave_preprocessed_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m save_preprocessed_tensors(test_dataset, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ¨ ëª¨ë“  ì „ì²˜ë¦¬ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m, in \u001b[0;36msave_preprocessed_tensors\u001b[0;34m(dataset, name)\u001b[0m\n\u001b[1;32m    101\u001b[0m all_images, all_labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ”¹ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ë°ì´í„° ì „ì²˜ë¦¬ ë° í…ì„œ ì €ì¥ ì¤‘...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loader):\n\u001b[1;32m    105\u001b[0m     all_images\u001b[38;5;241m.\u001b[39mappend(imgs)\n\u001b[1;32m    106\u001b[0m     all_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_58246/1468089281.py\", line 87, in __getitem__\n    raise FileNotFoundError(f\"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {img_path}\")\nFileNotFoundError: ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: /root/cv_project/data/train/002f99746285dfdd.jpg.jpg\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ“˜ Document Image Preprocessing Pipeline\n",
    "# ============================================================\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ============================================================\n",
    "# 1ï¸âƒ£ ì‹œë“œ ê³ ì • (ì¬í˜„ì„± ë³´ì¥)\n",
    "# ============================================================\n",
    "def set_seed(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ============================================================\n",
    "# 2ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "# ============================================================\n",
    "BASE_DIR = '/root/cv_project/data'\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, 'train.csv')\n",
    "TEST_CSV = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_IMG_DIR = os.path.join(BASE_DIR, 'test')\n",
    "\n",
    "SAVE_DIR = os.path.join(BASE_DIR, 'processed')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# 3ï¸âƒ£ Albumentations ì „ì²˜ë¦¬ ì •ì˜\n",
    "# ============================================================\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.Perspective(p=0.3),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# 4ï¸âƒ£ Custom Dataset\n",
    "# ============================================================\n",
    "class DocumentImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # ì»¬ëŸ¼ ìë™ íƒìƒ‰\n",
    "        self.id_col = [c for c in self.df.columns if 'id' in c.lower() or 'file' in c.lower()]\n",
    "        self.label_col = [c for c in self.df.columns if c.lower() in ['label', 'target', 'class']]\n",
    "\n",
    "        self.id_col = self.id_col[0] if self.id_col else self.df.columns[0]\n",
    "        self.label_col = self.label_col[0] if self.label_col else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = str(row[self.id_col])\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {img_path}\")\n",
    "\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        label = int(row[self.label_col]) if self.label_col else -1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# ============================================================\n",
    "# 5ï¸âƒ£ ë°ì´í„°ì…‹ ë¡œë“œ ë° ì €ì¥\n",
    "# ============================================================\n",
    "def save_preprocessed_tensors(dataset, name=\"train\"):\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    all_images, all_labels = [], []\n",
    "\n",
    "    print(f\"ğŸ”¹ {name} ë°ì´í„° ì „ì²˜ë¦¬ ë° í…ì„œ ì €ì¥ ì¤‘...\")\n",
    "    for imgs, labels in tqdm(loader):\n",
    "        all_images.append(imgs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_images = torch.cat(all_images)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    torch.save({\n",
    "        'images': all_images,\n",
    "        'labels': all_labels\n",
    "    }, os.path.join(SAVE_DIR, f'{name}_processed.pt'))\n",
    "\n",
    "    print(f\"âœ… {name}_processed.pt ì €ì¥ ì™„ë£Œ ({all_images.shape[0]}ê°œ ì´ë¯¸ì§€)\")\n",
    "\n",
    "# ============================================================\n",
    "# 6ï¸âƒ£ ì‹¤í–‰ (Train/Test ìë™ ì²˜ë¦¬)\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸ“˜ ë¬¸ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘\")\n",
    "\n",
    "    train_dataset = DocumentImageDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)\n",
    "    test_dataset = DocumentImageDataset(TEST_CSV, TEST_IMG_DIR, transform=test_transform)\n",
    "\n",
    "    save_preprocessed_tensors(train_dataset, name=\"train\")\n",
    "    save_preprocessed_tensors(test_dataset, name=\"test\")\n",
    "\n",
    "    print(\"âœ¨ ëª¨ë“  ì „ì²˜ë¦¬ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
