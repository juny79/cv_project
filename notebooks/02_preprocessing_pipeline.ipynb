{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930c6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 문서 이미지 전처리 파이프라인 시작\n",
      "🔹 train 데이터 전처리 및 텐서 저장 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_58246/1468089281.py\", line 87, in __getitem__\n    raise FileNotFoundError(f\"이미지 파일이 존재하지 않습니다: {img_path}\")\nFileNotFoundError: 이미지 파일이 존재하지 않습니다: /root/cv_project/data/train/002f99746285dfdd.jpg.jpg\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m DocumentImageDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform\u001b[38;5;241m=\u001b[39mtrain_transform)\n\u001b[1;32m    125\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DocumentImageDataset(TEST_CSV, TEST_IMG_DIR, transform\u001b[38;5;241m=\u001b[39mtest_transform)\n\u001b[0;32m--> 127\u001b[0m \u001b[43msave_preprocessed_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m save_preprocessed_tensors(test_dataset, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✨ 모든 전처리 완료 및 저장 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 104\u001b[0m, in \u001b[0;36msave_preprocessed_tensors\u001b[0;34m(dataset, name)\u001b[0m\n\u001b[1;32m    101\u001b[0m all_images, all_labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔹 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 데이터 전처리 및 텐서 저장 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loader):\n\u001b[1;32m    105\u001b[0m     all_images\u001b[38;5;241m.\u001b[39mappend(imgs)\n\u001b[1;32m    106\u001b[0m     all_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_58246/1468089281.py\", line 87, in __getitem__\n    raise FileNotFoundError(f\"이미지 파일이 존재하지 않습니다: {img_path}\")\nFileNotFoundError: 이미지 파일이 존재하지 않습니다: /root/cv_project/data/train/002f99746285dfdd.jpg.jpg\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 📘 Document Image Preprocessing Pipeline\n",
    "# ============================================================\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ============================================================\n",
    "# 1️⃣ 시드 고정 (재현성 보장)\n",
    "# ============================================================\n",
    "def set_seed(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ============================================================\n",
    "# 2️⃣ 경로 설정\n",
    "# ============================================================\n",
    "BASE_DIR = '/root/cv_project/data'\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, 'train.csv')\n",
    "TEST_CSV = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_IMG_DIR = os.path.join(BASE_DIR, 'test')\n",
    "\n",
    "SAVE_DIR = os.path.join(BASE_DIR, 'processed')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# 3️⃣ Albumentations 전처리 정의\n",
    "# ============================================================\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.Perspective(p=0.3),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# 4️⃣ Custom Dataset\n",
    "# ============================================================\n",
    "class DocumentImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 컬럼 자동 탐색\n",
    "        self.id_col = [c for c in self.df.columns if 'id' in c.lower() or 'file' in c.lower()]\n",
    "        self.label_col = [c for c in self.df.columns if c.lower() in ['label', 'target', 'class']]\n",
    "\n",
    "        self.id_col = self.id_col[0] if self.id_col else self.df.columns[0]\n",
    "        self.label_col = self.label_col[0] if self.label_col else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = str(row[self.id_col])\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"이미지 파일이 존재하지 않습니다: {img_path}\")\n",
    "\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        label = int(row[self.label_col]) if self.label_col else -1\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# ============================================================\n",
    "# 5️⃣ 데이터셋 로드 및 저장\n",
    "# ============================================================\n",
    "def save_preprocessed_tensors(dataset, name=\"train\"):\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    all_images, all_labels = [], []\n",
    "\n",
    "    print(f\"🔹 {name} 데이터 전처리 및 텐서 저장 중...\")\n",
    "    for imgs, labels in tqdm(loader):\n",
    "        all_images.append(imgs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_images = torch.cat(all_images)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    torch.save({\n",
    "        'images': all_images,\n",
    "        'labels': all_labels\n",
    "    }, os.path.join(SAVE_DIR, f'{name}_processed.pt'))\n",
    "\n",
    "    print(f\"✅ {name}_processed.pt 저장 완료 ({all_images.shape[0]}개 이미지)\")\n",
    "\n",
    "# ============================================================\n",
    "# 6️⃣ 실행 (Train/Test 자동 처리)\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"📘 문서 이미지 전처리 파이프라인 시작\")\n",
    "\n",
    "    train_dataset = DocumentImageDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)\n",
    "    test_dataset = DocumentImageDataset(TEST_CSV, TEST_IMG_DIR, transform=test_transform)\n",
    "\n",
    "    save_preprocessed_tensors(train_dataset, name=\"train\")\n",
    "    save_preprocessed_tensors(test_dataset, name=\"test\")\n",
    "\n",
    "    print(\"✨ 모든 전처리 완료 및 저장 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
