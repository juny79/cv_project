{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8593a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ ê³ ë„í™”ëœ ë¬¸ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘\n",
      "ğŸ”¹ train ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:40<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train_processed.pt ì €ì¥ ì™„ë£Œ (1570ê°œ ì´ë¯¸ì§€)\n",
      "ğŸ”¹ test ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [01:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… test_processed.pt ì €ì¥ ì™„ë£Œ (3140ê°œ ì´ë¯¸ì§€)\n",
      "âœ¨ ëª¨ë“  ì „ì²˜ë¦¬ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ (F1-Optimized v2, fixed)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ğŸ“˜ Document Image Preprocessing Pipeline v2 (F1-Optimized, Fixed)\n",
    "# ============================================================\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# -------------------- 1) ì¬í˜„ì„± --------------------\n",
    "def set_seed(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# -------------------- 2) ê²½ë¡œ --------------------\n",
    "BASE_DIR = '/root/cv_project/data'\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, 'train.csv')\n",
    "TEST_CSV  = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, 'train')\n",
    "TEST_IMG_DIR  = os.path.join(BASE_DIR, 'test')\n",
    "SAVE_DIR = os.path.join(BASE_DIR, 'processed_v2')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------- 3) ìœ í‹¸ --------------------\n",
    "COMMON_EXTS = ['.jpg', '.jpeg', '.png', '.JPG', '.PNG', '.JPEG']\n",
    "\n",
    "def has_ext(name: str) -> bool:\n",
    "    return os.path.splitext(name)[1] != ''\n",
    "\n",
    "def resolve_image_path(img_dir: str, name: str) -> str:\n",
    "    \"\"\"\n",
    "    CSVì˜ id/file/pathê°€\n",
    "    - ì ˆëŒ€ê²½ë¡œ\n",
    "    - ìƒëŒ€ê²½ë¡œ\n",
    "    - í™•ì¥ì í¬í•¨/ë¯¸í¬í•¨\n",
    "    - í™•ì¥ì ëŒ€ì†Œë¬¸ì í˜¼ì¬\n",
    "    ì „ë¶€ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ì—¬ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²½ë¡œë¥¼ ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    # ì ˆëŒ€ê²½ë¡œë¡œ ì´ë¯¸ ì¡´ì¬?\n",
    "    if os.path.isabs(name) and os.path.exists(name):\n",
    "        return name\n",
    "\n",
    "    base_name = os.path.basename(str(name))\n",
    "    # 1) ê·¸ëŒ€ë¡œ ê²°í•©\n",
    "    cand = os.path.join(img_dir, base_name)\n",
    "    candidates = [cand]\n",
    "\n",
    "    root, ext = os.path.splitext(base_name)\n",
    "    if has_ext(base_name):\n",
    "        # í™•ì¥ì ë°”ê¿”ê°€ë©° ì¡´ì¬ í™•ì¸ (csv í™•ì¥ìì™€ ì‹¤ì œ íŒŒì¼ í™•ì¥ìê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)\n",
    "        for e in COMMON_EXTS:\n",
    "            candidates.append(os.path.join(img_dir, root + e))\n",
    "    else:\n",
    "        # í™•ì¥ì ì—†ìœ¼ë©´ ëŒ€í‘œ í™•ì¥ì ë¶™ì—¬ê°€ë©° í™•ì¸\n",
    "        for e in COMMON_EXTS:\n",
    "            candidates.append(os.path.join(img_dir, base_name + e))\n",
    "\n",
    "    # ì¤‘ë³µ ì œê±°í•˜ë©° ì¡´ì¬ í™•ì¸\n",
    "    seen = set()\n",
    "    for p in candidates:\n",
    "        if p in seen: \n",
    "            continue\n",
    "        seen.add(p)\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "\n",
    "    # ë””ë²„ê¹… ë„ì›€: ì‹œë„í•œ í›„ë³´ ì•ˆë‚´\n",
    "    raise FileNotFoundError(\n",
    "        f\"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. name='{name}', img_dir='{img_dir}'\\n\"\n",
    "        f\"ì‹œë„í•œ í›„ë³´ ì˜ˆ: {candidates[:5]} ...\"\n",
    "    )\n",
    "\n",
    "# -------------------- 4) ì „ì²˜ë¦¬ í•¨ìˆ˜ (lambda ëŒ€ì²´) --------------------\n",
    "def deskew_cv(image, **kwargs):   # â† **kwargs ì¶”ê°€\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    coords = np.column_stack(np.where(gray > 0))\n",
    "    if coords.size == 0:\n",
    "        return image\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h),\n",
    "                             flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def apply_clahe_cv(image, **kwargs):   # â† **kwargs ì¶”ê°€\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def resize_with_padding_512(image, **kwargs):   # â† **kwargs ì¶”ê°€\n",
    "    target_size = 512\n",
    "    h, w = image.shape[:2]\n",
    "    if max(h, w) == 0:\n",
    "        return cv2.resize(image, (target_size, target_size))\n",
    "    scale = target_size / max(h, w)\n",
    "    nh, nw = int(h * scale), int(w * scale)\n",
    "    resized = cv2.resize(image, (nw, nh))\n",
    "    pad_h = (target_size - nh) // 2\n",
    "    pad_w = (target_size - nw) // 2\n",
    "    padded = cv2.copyMakeBorder(resized,\n",
    "                                pad_h, target_size - nh - pad_h,\n",
    "                                pad_w, target_size - nw - pad_w,\n",
    "                                cv2.BORDER_CONSTANT, value=255)\n",
    "    return padded\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- 5) Albumentations (lambda ì œê±°) --------------------\n",
    "train_transform = A.Compose([\n",
    "    A.Lambda(image=deskew_cv, p=0.5),\n",
    "    A.Lambda(image=apply_clahe_cv, p=0.5),\n",
    "    A.RandomShadow(p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.ImageCompression(quality_lower=60, quality_upper=100, p=0.3),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.Perspective(scale=(0.02, 0.05), p=0.3),\n",
    "    A.Rotate(limit=8, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n",
    "    A.Lambda(image=resize_with_padding_512, p=1.0),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Lambda(image=deskew_cv, p=1.0),\n",
    "    A.Lambda(image=apply_clahe_cv, p=1.0),\n",
    "    A.Lambda(image=resize_with_padding_512, p=1.0),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------- 6) Dataset --------------------\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.id_col = [c for c in self.df.columns if any(k in c.lower() for k in ['id','file','path','image'])]\n",
    "        self.label_col = [c for c in self.df.columns if c.lower() in ['label','target','class']]\n",
    "        self.id_col = self.id_col[0] if self.id_col else self.df.columns[0]\n",
    "        self.label_col = self.label_col[0] if self.label_col else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        name = str(row[self.id_col])\n",
    "        img_path = resolve_image_path(self.img_dir, name)   # âœ… ì•ˆì „ ê²½ë¡œ íƒìƒ‰ (í™•ì¥ì ì´ì¤‘ ë°©ì§€)\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        label = int(row[self.label_col]) if self.label_col else -1\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# -------------------- 7) ì €ì¥ --------------------\n",
    "def save_preprocessed_tensors(dataset, name=\"train\", batch_size=32, num_workers=0):\n",
    "    # âš  lambda ê²½ê³  íšŒí”¼: num_workers=0 ê¶Œì¥(ë˜ëŠ” ìœ„ì—ì„œ lambda ì œê±°í–ˆìœ¼ë‹ˆ 2~4ë„ ê°€ëŠ¥)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    all_images, all_labels = [], []\n",
    "\n",
    "    print(f\"ğŸ”¹ {name} ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "    for imgs, labels in tqdm(loader):\n",
    "        all_images.append(imgs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    all_images = torch.cat(all_images)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    torch.save({'images': all_images, 'labels': all_labels},\n",
    "               os.path.join(SAVE_DIR, f\"{name}_processed.pt\"))\n",
    "    print(f\"âœ… {name}_processed.pt ì €ì¥ ì™„ë£Œ ({all_images.shape[0]}ê°œ ì´ë¯¸ì§€)\")\n",
    "\n",
    "# -------------------- 8) ì‹¤í–‰ --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸ“˜ ê³ ë„í™”ëœ ë¬¸ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘\")\n",
    "\n",
    "    train_ds = DocumentDataset(TRAIN_CSV, TRAIN_IMG_DIR, transform=train_transform)\n",
    "    test_ds  = DocumentDataset(TEST_CSV,  TEST_IMG_DIR,  transform=test_transform)\n",
    "\n",
    "    # ì²« ì‹¤í–‰ì€ num_workers=0 ê¶Œì¥ (ê²½ê³ /ê²½ë¡œ ë¬¸ì œ í™•ì‹¤íˆ í•´ê²° í›„ ëŠ˜ë ¤ë„ ë¨)\n",
    "    save_preprocessed_tensors(train_ds, name=\"train\", num_workers=0)\n",
    "    save_preprocessed_tensors(test_ds,  name=\"test\",  num_workers=0)\n",
    "\n",
    "    print(\"âœ¨ ëª¨ë“  ì „ì²˜ë¦¬ ì™„ë£Œ ë° ì €ì¥ ì™„ë£Œ (F1-Optimized v2, fixed)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
